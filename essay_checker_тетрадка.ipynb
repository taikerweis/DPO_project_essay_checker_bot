{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14e74f17",
   "metadata": {},
   "source": [
    "Телеграм-бот – помощник по проверке сочинений для ЕГЭ по русскому по критериям 2025 года"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f35897e",
   "metadata": {},
   "source": [
    "Библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "761204de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:14: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 2.3.1)\n",
      "  from scipy.sparse import csr_matrix, issparse\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, Trainer, TrainingArguments, DataCollatorWithPadding, EarlyStoppingCallback\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils import class_weight\n",
    "from safetensors.torch import load_file\n",
    "from telegram import Update\n",
    "from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895b6794",
   "metadata": {},
   "source": [
    "Обучение: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8776a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:14: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 2.3.1)\n",
      "  from scipy.sparse import csr_matrix, issparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               essay  K1  K2  K3  K4  K5  K6  \\\n",
      "0  В чём состоят цели творчества художника? Именн...   1   3   2   1   2   1   \n",
      "1  А.П. Чехов в предложенном фрагменте пьесы «Дяд...   0   0   0   1   1   1   \n",
      "2  В своем произведении Ю.К. Олеша задается вопро...   1   3   2   1   2   1   \n",
      "3  Настоящая критика… Какой она должна быть? Имен...   1   3   2   1   2   1   \n",
      "4  В центре внимания А.С. Новикова-Прибоя находит...   1   3   2   1   2   1   \n",
      "\n",
      "   K7  K8  K9  K10  total_score  \n",
      "0   3   3   3    3           22  \n",
      "1   1   2   3    3           12  \n",
      "2   3   2   2    3           20  \n",
      "3   3   3   3    3           22  \n",
      "4   3   3   3    3           22  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 233/233 [00:00<00:00, 3135.41 examples/s]\n",
      "C:\\Users\\taike\\AppData\\Local\\Temp\\ipykernel_64348\\1560556830.py:148: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156/180 04:32 < 00:42, 0.57 it/s, Epoch 13/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Mean</th>\n",
       "      <th>F1 Macro Mean</th>\n",
       "      <th>Accuracy Per Criterion</th>\n",
       "      <th>F1 Macro Per Criterion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.071264</td>\n",
       "      <td>0.612766</td>\n",
       "      <td>0.369377</td>\n",
       "      <td>[0.9787234042553191, 0.9787234042553191, 0.9148936170212766, 0.02127659574468085, 0.0, 0.9787234042553191, 0.0, 0.2765957446808511, 1.0, 0.9787234042553191]</td>\n",
       "      <td>[0.4946236559139785, 0.4946236559139785, 0.4777777777777778, 0.020833333333333332, 0.0, 0.4946236559139785, 0.0, 0.21666666666666667, 1.0, 0.4946236559139785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.055602</td>\n",
       "      <td>0.644681</td>\n",
       "      <td>0.384771</td>\n",
       "      <td>[0.9787234042553191, 0.9787234042553191, 0.9361702127659575, 0.02127659574468085, 0.0, 0.9787234042553191, 0.0, 0.574468085106383, 1.0, 0.9787234042553191]</td>\n",
       "      <td>[0.4946236559139785, 0.4946236559139785, 0.4835164835164835, 0.020833333333333332, 0.0, 0.4946236559139785, 0.0, 0.36486486486486486, 1.0, 0.4946236559139785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.039974</td>\n",
       "      <td>0.661702</td>\n",
       "      <td>0.391649</td>\n",
       "      <td>[0.9787234042553191, 0.9787234042553191, 0.9361702127659575, 0.02127659574468085, 0.02127659574468085, 0.9787234042553191, 0.0, 0.723404255319149, 1.0, 0.9787234042553191]</td>\n",
       "      <td>[0.4946236559139785, 0.4946236559139785, 0.4835164835164835, 0.020833333333333332, 0.013888888888888888, 0.4946236559139785, 0.0, 0.41975308641975306, 1.0, 0.4946236559139785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.026700</td>\n",
       "      <td>0.682979</td>\n",
       "      <td>0.401099</td>\n",
       "      <td>[0.9787234042553191, 0.9787234042553191, 0.9574468085106383, 0.02127659574468085, 0.1276595744680851, 0.9787234042553191, 0.0, 0.8085106382978723, 1.0, 0.9787234042553191]</td>\n",
       "      <td>[0.4946236559139785, 0.4946236559139785, 0.4891304347826087, 0.020833333333333332, 0.07547169811320754, 0.4946236559139785, 0.0, 0.4470588235294118, 1.0, 0.4946236559139785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.015461</td>\n",
       "      <td>0.719149</td>\n",
       "      <td>0.419149</td>\n",
       "      <td>[0.9787234042553191, 0.9787234042553191, 0.9787234042553191, 0.02127659574468085, 0.2553191489361702, 0.9787234042553191, 0.0851063829787234, 0.9361702127659575, 1.0, 0.9787234042553191]</td>\n",
       "      <td>[0.4946236559139785, 0.4946236559139785, 0.4946236559139785, 0.020833333333333332, 0.13559322033898305, 0.4946236559139785, 0.0784313725490196, 0.4835164835164835, 1.0, 0.4946236559139785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.004193</td>\n",
       "      <td>0.751064</td>\n",
       "      <td>0.437433</td>\n",
       "      <td>[0.9787234042553191, 0.9787234042553191, 0.9787234042553191, 0.0851063829787234, 0.425531914893617, 0.9787234042553191, 0.14893617021276595, 0.9574468085106383, 1.0, 0.9787234042553191]</td>\n",
       "      <td>[0.4946236559139785, 0.4946236559139785, 0.4946236559139785, 0.08344671201814059, 0.1990049751243781, 0.4946236559139785, 0.12962962962962962, 0.4891304347826087, 1.0, 0.4946236559139785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.994631</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.460558</td>\n",
       "      <td>[0.9787234042553191, 0.9787234042553191, 0.9787234042553191, 0.2127659574468085, 0.48936170212765956, 0.9787234042553191, 0.2978723404255319, 0.9787234042553191, 1.0, 0.9787234042553191]</td>\n",
       "      <td>[0.4946236559139785, 0.4946236559139785, 0.4946236559139785, 0.18927738927738927, 0.21904761904761905, 0.4946236559139785, 0.22950819672131148, 0.4946236559139785, 1.0, 0.4946236559139785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.986550</td>\n",
       "      <td>0.846809</td>\n",
       "      <td>0.541051</td>\n",
       "      <td>[0.9787234042553191, 0.9787234042553191, 0.9787234042553191, 0.46808510638297873, 0.5957446808510638, 0.9787234042553191, 0.5106382978723404, 1.0, 1.0, 0.9787234042553191]</td>\n",
       "      <td>[0.4946236559139785, 0.4946236559139785, 0.4946236559139785, 0.3504698728579326, 0.2488888888888889, 0.4946236559139785, 0.3380281690140845, 1.0, 1.0, 0.4946236559139785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.979505</td>\n",
       "      <td>0.885106</td>\n",
       "      <td>0.560001</td>\n",
       "      <td>[0.9787234042553191, 0.9787234042553191, 0.9787234042553191, 0.7446808510638298, 0.5957446808510638, 0.9787234042553191, 0.6170212765957447, 1.0, 1.0, 0.9787234042553191]</td>\n",
       "      <td>[0.4946236559139785, 0.4946236559139785, 0.4946236559139785, 0.49642857142857144, 0.2488888888888889, 0.4946236559139785, 0.3815789473684211, 1.0, 1.0, 0.4946236559139785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.973502</td>\n",
       "      <td>0.919149</td>\n",
       "      <td>0.589549</td>\n",
       "      <td>[0.9787234042553191, 0.9787234042553191, 0.9787234042553191, 0.8723404255319149, 0.7021276595744681, 0.9787234042553191, 0.723404255319149, 1.0, 1.0, 0.9787234042553191]</td>\n",
       "      <td>[0.4946236559139785, 0.4946236559139785, 0.4946236559139785, 0.5901162790697674, 0.4125, 0.4946236559139785, 0.41975308641975306, 1.0, 1.0, 0.4946236559139785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.968854</td>\n",
       "      <td>0.940426</td>\n",
       "      <td>0.616826</td>\n",
       "      <td>[0.9787234042553191, 0.9787234042553191, 0.9787234042553191, 0.9787234042553191, 0.7446808510638298, 0.9787234042553191, 0.7872340425531915, 1.0, 1.0, 0.9787234042553191]</td>\n",
       "      <td>[0.4946236559139785, 0.4946236559139785, 0.4946236559139785, 0.8278388278388278, 0.4268292682926829, 0.4946236559139785, 0.44047619047619047, 1.0, 1.0, 0.4946236559139785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.964983</td>\n",
       "      <td>0.953191</td>\n",
       "      <td>0.587339</td>\n",
       "      <td>[0.9787234042553191, 0.9787234042553191, 0.9787234042553191, 0.9787234042553191, 0.7659574468085106, 0.9787234042553191, 0.8936170212765957, 1.0, 1.0, 0.9787234042553191]</td>\n",
       "      <td>[0.4946236559139785, 0.4946236559139785, 0.4946236559139785, 0.4946236559139785, 0.43373493975903615, 0.4946236559139785, 0.47191011235955055, 1.0, 1.0, 0.4946236559139785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.962373</td>\n",
       "      <td>0.955319</td>\n",
       "      <td>0.587925</td>\n",
       "      <td>[0.9787234042553191, 0.9787234042553191, 0.9787234042553191, 0.9787234042553191, 0.7659574468085106, 0.9787234042553191, 0.9148936170212766, 1.0, 1.0, 0.9787234042553191]</td>\n",
       "      <td>[0.4946236559139785, 0.4946236559139785, 0.4946236559139785, 0.4946236559139785, 0.43373493975903615, 0.4946236559139785, 0.4777777777777778, 1.0, 1.0, 0.4946236559139785]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.9688538908958435, 'eval_accuracy_mean': 0.9404255319148935, 'eval_f1_macro_mean': 0.6168262566177594, 'eval_accuracy_per_criterion': [0.9787234042553191, 0.9787234042553191, 0.9787234042553191, 0.9787234042553191, 0.7446808510638298, 0.9787234042553191, 0.7872340425531915, 1.0, 1.0, 0.9787234042553191], 'eval_f1_macro_per_criterion': [0.4946236559139785, 0.4946236559139785, 0.4946236559139785, 0.8278388278388278, 0.4268292682926829, 0.4946236559139785, 0.44047619047619047, 1.0, 1.0, 0.4946236559139785], 'eval_runtime': 0.4542, 'eval_samples_per_second': 103.47, 'eval_steps_per_second': 6.604, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (47, 10)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "CRITERIA = [f\"K{i}\" for i in range(1, 11)]\n",
    "NUM_CLASSES = [2, 4, 3, 2, 3, 2, 4, 4, 4, 4]\n",
    "\n",
    "df = pd.read_csv(\"sochineniya_score.csv\", sep=';')\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "data_dict = {\n",
    "    \"essay\": df[\"essay\"].tolist(),\n",
    "    \"labels\": df[CRITERIA].values.tolist()\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data_dict)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    encodings = tokenizer(examples[\"essay\"], truncation=True, padding=False)\n",
    "    encodings[\"labels\"] = examples[\"labels\"]\n",
    "    return encodings\n",
    "\n",
    "dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split[\"train\"]\n",
    "val_dataset = split[\"test\"]\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def compute_class_weights_safe(y, num_classes, device='cpu'):\n",
    "    unique_classes = np.unique(y)\n",
    "    weights_existing = class_weight.compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=unique_classes,\n",
    "        y=y\n",
    "    )\n",
    "    weights_full = np.ones(num_classes, dtype=np.float32)\n",
    "    for cls, w in zip(unique_classes, weights_existing):\n",
    "        weights_full[cls] = w\n",
    "    weights_tensor = torch.tensor(weights_full, dtype=torch.float32, device=device)\n",
    "    return weights_tensor\n",
    "\n",
    "class_weights_per_criterion = []\n",
    "for i, crit in enumerate(CRITERIA):\n",
    "    num_classes = NUM_CLASSES[i]\n",
    "    labels = df[crit].values.astype(int) \n",
    "    weights_tensor = compute_class_weights_safe(labels, num_classes, device=device)\n",
    "    class_weights_per_criterion.append(weights_tensor)\n",
    "\n",
    "def set_zeros_for_short_essays(essays, preds):\n",
    "    for i, essay in enumerate(essays):\n",
    "        if len(essay.split()) < 150:\n",
    "            preds[i] = np.zeros(preds.shape[1], dtype=int)\n",
    "    return preds\n",
    "\n",
    "class MultiHeadRubertModel(nn.Module):\n",
    "    def __init__(self, class_weights):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Linear(self.bert.config.hidden_size, num_class) for num_class in NUM_CLASSES\n",
    "        ])\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output  \n",
    "        logits_list = [head(pooled_output) for head in self.heads]\n",
    "\n",
    "        if labels is not None:\n",
    "            total_loss = 0\n",
    "            for i, logits in enumerate(logits_list):\n",
    "                loss_fct = nn.CrossEntropyLoss(weight=self.class_weights[i])\n",
    "                total_loss += loss_fct(logits, labels[:, i])\n",
    "            loss = total_loss / len(self.heads)\n",
    "            return {\"loss\": loss, \"logits\": logits_list}\n",
    "        else:\n",
    "            return {\"logits\": logits_list}\n",
    "\n",
    "model = MultiHeadRubertModel(class_weights=class_weights_per_criterion).to(device)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits_list, labels = eval_pred\n",
    "    preds = []\n",
    "    for i in range(len(NUM_CLASSES)):\n",
    "        preds_i = np.argmax(logits_list[i], axis=1)\n",
    "        preds.append(preds_i)\n",
    "    preds = np.stack(preds, axis=1)\n",
    "\n",
    "    acc_list, f1_list = [], []\n",
    "    for i in range(len(NUM_CLASSES)):\n",
    "        acc = accuracy_score(labels[:, i], preds[:, i])\n",
    "        f1 = f1_score(labels[:, i], preds[:, i], average=\"macro\")\n",
    "        acc_list.append(acc)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    return {\n",
    "        \"accuracy_mean\": np.mean(acc_list),\n",
    "        \"f1_macro_mean\": np.mean(f1_list),\n",
    "        \"accuracy_per_criterion\": acc_list,\n",
    "        \"f1_macro_per_criterion\": f1_list,\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=4e-5,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=15,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro_mean\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "eval_result = trainer.evaluate()\n",
    "print(\"Evaluation results:\", eval_result)\n",
    "\n",
    "pred_output = trainer.predict(val_dataset)\n",
    "\n",
    "logits_list = pred_output.predictions\n",
    "\n",
    "if isinstance(logits_list, list):\n",
    "    preds_per_criterion = [np.argmax(logits, axis=1) for logits in logits_list]\n",
    "    preds = np.stack(preds_per_criterion, axis=1)\n",
    "else:\n",
    "    print(\"Warning: pred_output.predictions is not list.\")\n",
    "    preds = None  \n",
    "\n",
    "essays = val_dataset[\"essay\"]\n",
    "preds = set_zeros_for_short_essays(essays, preds)\n",
    "\n",
    "print(\"Predictions shape:\", preds.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49811b",
   "metadata": {},
   "source": [
    "Телеграм-бот:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d48c9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msafetensors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_file\n",
      "File \u001b[1;32mc:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\__init__.py:2611\u001b[0m\n\u001b[0;32m   2607\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vmap \u001b[38;5;28;01mas\u001b[39;00m vmap\n\u001b[0;32m   2610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m-> 2611\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations\n\u001b[0;32m   2613\u001b[0m \u001b[38;5;66;03m# Enable CUDA Sanitizer\u001b[39;00m\n\u001b[0;32m   2614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCH_CUDA_SANITIZER\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n",
      "File \u001b[1;32mc:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_meta_registrations.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims_common\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SymBool, SymFloat, Tensor\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     13\u001b[0m     _add_op_to_registry,\n\u001b[0;32m     14\u001b[0m     _convert_out_params,\n\u001b[0;32m     15\u001b[0m     global_decomposition_table,\n\u001b[0;32m     16\u001b[0m     meta_table,\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpOverload\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _prim_elementwise_meta, ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\n",
      "File \u001b[1;32mc:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_decomp\\__init__.py:277\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m# populate the table\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecompositions\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_refs\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcore_aten_decompositions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomDecompTable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexported_program\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m default_decompositions\n",
      "File \u001b[1;32mc:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_refs\\__init__.py:3223\u001b[0m\n\u001b[0;32m   3218\u001b[0m     rstd \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(rstd, reduction_dims)\n\u001b[0;32m   3219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (out, mean, rstd)\n\u001b[0;32m   3222\u001b[0m \u001b[38;5;129;43m@register_decomposition\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maten\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnative_layer_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m-> 3223\u001b[0m \u001b[38;5;129;43m@out_wrapper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mout0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mout1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mout2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3224\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mnative_layer_norm\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mShapeType\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3229\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3230\u001b[0m \u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalized_ndim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalized_ndim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3234\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExpected normalized_shape to be at least 1-dimensional, i.e., \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m   3235\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontaining at least one element, but got normalized_shape = \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m   3236\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_prims_common\\wrappers.py:283\u001b[0m, in \u001b[0;36mout_wrapper.<locals>._out_wrapper\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m    268\u001b[0m bc_out_type \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    269\u001b[0m     TensorLikeType\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_tensor\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    273\u001b[0m     )\n\u001b[0;32m    274\u001b[0m )\n\u001b[0;32m    275\u001b[0m return_type \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    276\u001b[0m     TensorLikeType\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_tensor\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[0;32m    281\u001b[0m )\n\u001b[1;32m--> 283\u001b[0m sig \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m factory_kwargs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    285\u001b[0m is_factory_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(p \u001b[38;5;129;01min\u001b[39;00m sig\u001b[38;5;241m.\u001b[39mparameters \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m factory_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\inspect.py:3327\u001b[0m, in \u001b[0;36msignature\u001b[1;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[0;32m   3325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msignature\u001b[39m(obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   3326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3328\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\inspect.py:3071\u001b[0m, in \u001b[0;36mSignature.from_callable\u001b[1;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   3068\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_callable\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   3069\u001b[0m                   follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   3070\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3071\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigcls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3072\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mfollow_wrapper_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3073\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\inspect.py:2559\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[1;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[0;32m   2554\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m sig\u001b[38;5;241m.\u001b[39mreplace(parameters\u001b[38;5;241m=\u001b[39mnew_params)\n\u001b[0;32m   2556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isfunction(obj) \u001b[38;5;129;01mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[0;32m   2557\u001b[0m     \u001b[38;5;66;03m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[0;32m   2558\u001b[0m     \u001b[38;5;66;03m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[1;32m-> 2559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2560\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mskip_bound_arg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_bound_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2561\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _signature_is_builtin(obj):\n\u001b[0;32m   2564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_builtin(sigcls, obj,\n\u001b[0;32m   2565\u001b[0m                                    skip_bound_arg\u001b[38;5;241m=\u001b[39mskip_bound_arg)\n",
      "File \u001b[1;32mc:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\inspect.py:2413\u001b[0m, in \u001b[0;36m_signature_from_function\u001b[1;34m(cls, func, skip_bound_arg, globals, locals, eval_str)\u001b[0m\n\u001b[0;32m   2411\u001b[0m kind \u001b[38;5;241m=\u001b[39m _POSITIONAL_ONLY \u001b[38;5;28;01mif\u001b[39;00m posonly_left \u001b[38;5;28;01melse\u001b[39;00m _POSITIONAL_OR_KEYWORD\n\u001b[0;32m   2412\u001b[0m annotation \u001b[38;5;241m=\u001b[39m annotations\u001b[38;5;241m.\u001b[39mget(name, _empty)\n\u001b[1;32m-> 2413\u001b[0m parameters\u001b[38;5;241m.\u001b[39mappend(\u001b[43mParameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2414\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m posonly_left:\n\u001b[0;32m   2416\u001b[0m     posonly_left \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\inspect.py:2731\u001b[0m, in \u001b[0;36mParameter.__init__\u001b[1;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[0;32m   2729\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, kind, \u001b[38;5;241m*\u001b[39m, default\u001b[38;5;241m=\u001b[39m_empty, annotation\u001b[38;5;241m=\u001b[39m_empty):\n\u001b[0;32m   2730\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2731\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kind \u001b[38;5;241m=\u001b[39m \u001b[43m_ParameterKind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2732\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   2733\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkind\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not a valid Parameter.kind\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\taike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\enum.py:709\u001b[0m, in \u001b[0;36mEnumType.__call__\u001b[1;34m(cls, value, names, module, qualname, type, start, boundary, *values)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03m    classes/types should always be True.\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, value, names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39mvalues, module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, qualname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, boundary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    710\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;124;03m    Either returns an existing member, or creates a new enum class.\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;124;03m    `type`, if set, will be mixed in as the first base class.\u001b[39;00m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_member_map_:\n\u001b[0;32m    737\u001b[0m         \u001b[38;5;66;03m# simple value lookup if members exist\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = [2, 4, 3, 2, 3, 2, 4, 4, 4, 4]\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "BOT_TOKEN = \"7687048119:AAGzDXtsD405uqd13Fh5mHRP4KztkVGtXDw\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "CRITERIA = [f\"K{i}\" for i in range(1, 11)]\n",
    "\n",
    "explanations_dict = {\n",
    "    \"K1\": {0: \"Позиция автора не сформулирована.\", 1: \"Позиция автора сформулирована верно.\"},\n",
    "    \"K2\": {0: \"Позиция автора не сформулирована, или не приведены примеры-иллюстрации, или не даны пояснения к ним.\",\n",
    "           1: \"Позиция автора (рассказчика) по указанной проблеме исходного текста прокомментирована с опорой на исходный текст. Приведён 1 пример-иллюстрация из прочитанного текста, важный для понимания позиции автора (рассказчика) по указанной проблеме исходного текста. Дано пояснение к этому примеру-иллюстрации.\",\n",
    "           2: \"Позиция автора (рассказчика) по указанной проблеме исходного текста прокомментирована с опорой на исходный текст. Приведено 2 примера-иллюстрации из прочитанного текста, важных для понимания позиции автора (рассказчика) по указанной проблеме исходного текста. Дано пояснение к каждому из примеров-иллюстраций.Смысловая связь между приведёнными примерами-иллюстрациями не указана, или не дано её пояснение, или дано неверное пояснение.\",\n",
    "           3: \"Позиция автора (рассказчика) по указанной проблеме исходного текста прокомментирована с опорой на исходный текст. Приведено 2 примера-иллюстрации из прочитанного текста, важных для понимания позиции автора (рассказчика) по указанной проблеме исходного текста. Дано пояснение к каждому из примеров-иллюстраций. Указана смысловая связь между приведёнными примерами-иллюстрациями. Дано пояснение к ней.\"},\n",
    "    \"K3\": {0: \"Собственное отношение к позиции автора (рассказчика) по указанной проблеме исходного текста не сформулировано и не обосновано.\",\n",
    "           1: \"Собственное отношение к позиции автора (рассказчика) по указанной проблеме исходного текста сформулировано и обосновано. Пример-аргумент не приведён.\",\n",
    "           2: \"Собственное отношение к позиции автора (рассказчика) по указанной проблеме исходного текста сформулировано и обосновано. Приведён пример-аргумент.\"},\n",
    "    \"K4\": {0: \"Допущена одна фактическая ошибка или более.\", 1: \"Фактические ошибки отсутствуют.\"},\n",
    "    \"K5\": {0: \"Допущены две логические ошибки или более.\", 1: \"Допущена одна логическая ошибка.\", 2: \"Логические ошибки отсутствуют\"},\n",
    "    \"K6\": {0: \"В работе приводятся примеры экстремистских и/или иных запрещённых к производству и распространению среди несовершеннолетних материалов / социально неприемлемого поведения людей / имеются высказывания, нарушающие законодательство Российской Федерации.\", 1: \"Этические ошибки отсутствуют.\"},\n",
    "    \"K7\": {0: \"Допущены пять орфографических ошибок или более\", 1: \"Допущены три-четыре орфографические ошибки.\", 2: \"Допущены одна-две орфографические ошибки.\", 3: \"Орфографических ошибок нет.\"},\n",
    "    \"K8\": {0: \"Допущены пять пунктуационных ошибок или более\", 1: \"Допущены три-четыре пунктуационные ошибки.\", 2: \"Допущены одна-две пунктуационные ошибки.\", 3: \"Пунктуационных ошибок нет.\"},\n",
    "    \"K9\": {0: \"Допущены пять грамматических ошибок или более\", 1: \"Допущены три-четыре грамматические ошибки.\", 2: \"Допущены одна-две грамматические ошибки.\", 3: \"Грамматических ошибок нет.\"},\n",
    "    \"K10\": {0: \"Допущены пять речевых ошибок или более\", 1: \"Допущены три-четыре речевые ошибки.\", 2: \"Допущены одна-две речевые ошибки.\", 3: \"Речевых ошибок нет.\"}\n",
    "}\n",
    "\n",
    "\n",
    "class MultiHeadRubertModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Linear(self.bert.config.hidden_size, num_class) for num_class in NUM_CLASSES\n",
    "        ])\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output \n",
    "        logits_list = [head(pooled_output) for head in self.heads]\n",
    "        return logits_list\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = MultiHeadRubertModel()\n",
    "\n",
    "checkpoints_path = \"C:/Users/taike/OneDrive/Рабочий стол/Final project/output\"\n",
    "checkpoint_dirs = [d for d in os.listdir(checkpoints_path) if d.startswith(\"checkpoint-\")]\n",
    "latest_checkpoint = max(checkpoint_dirs, key=lambda x: int(x.split(\"-\")[1]))\n",
    "model_path = os.path.join(checkpoints_path, latest_checkpoint, \"model.safetensors\")\n",
    "\n",
    "state_dict = load_file(model_path, device=DEVICE)\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(torch.device(DEVICE)) \n",
    "model.eval()\n",
    "\n",
    "\n",
    "def predict_and_explain(text: str):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits_list = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "\n",
    "    preds = [torch.argmax(logits, dim=-1).item() for logits in logits_list]\n",
    "\n",
    "    explanations = []\n",
    "    for i, crit in enumerate(CRITERIA):\n",
    "        pred_class = preds[i]\n",
    "        explanation = explanations_dict.get(crit, {}).get(pred_class, f\"Балл {pred_class} по критерию {crit}\")\n",
    "        explanations.append((crit, pred_class, explanation))\n",
    "\n",
    "    total_score = sum(preds)\n",
    "    return preds, explanations, total_score\n",
    "\n",
    "\n",
    "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    await update.message.reply_text(\"Привет! Пришли мне текст сочинения, и я оценю его по 10 критериям.\")\n",
    "\n",
    "async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    text = update.message.text\n",
    "    if not text or text.strip() == \"\":\n",
    "        await update.message.reply_text(\"Пожалуйста, пришли текст сочинения для оценки.\")\n",
    "        return\n",
    "\n",
    "    if len(text.split()) < 150:\n",
    "        await update.message.reply_text(\"Итоговый балл: 0. В сочинении меньше 150 слов. Нужно увеличить его объём.\")\n",
    "        return\n",
    "\n",
    "    preds, explanations, total_score = predict_and_explain(text)\n",
    "\n",
    "    reply = [f\"Итоговый балл: {total_score}\\n\"]\n",
    "    for crit, pred, expl in explanations:\n",
    "        reply.append(f\"{crit}: {pred}\\n{expl}\\n\")\n",
    "\n",
    "    await update.message.reply_text(\"\\n\".join(reply))\n",
    "\n",
    "async def main():\n",
    "    app = ApplicationBuilder().token(BOT_TOKEN).build()\n",
    "    app.add_handler(CommandHandler(\"start\", start))\n",
    "    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n",
    "\n",
    "    print(\"Бот запущен. Ожидаю сообщения...\")\n",
    "    await app.run_polling()\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
